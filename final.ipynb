{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": false,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "sample_submission = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **train and test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.iloc[:,2:]\n",
    "y_train = train['target']\n",
    "x_test = test.iloc[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_feature shape: (200000, 200)\n",
      "train_target shape: (200000,)\n",
      "test_feature shape: (200000, 200)\n"
     ]
    }
   ],
   "source": [
    "print('train_feature shape:', x_train.shape)\n",
    "print('train_target shape:', y_train.shape)\n",
    "print('test_feature shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment sample to deal with the imbalanced dataset\n",
    "def disarrange(a, axis=-1):\n",
    "    \"\"\"\n",
    "    Shuffle `a` in-place along the given axis.\n",
    "\n",
    "    Apply numpy.random.shuffle to the given axis of `a`.\n",
    "    Each one-dimensional slice is shuffled independently.\n",
    "    \"\"\"\n",
    "    b = a.swapaxes(axis, -1)\n",
    "    # Shuffle `b` in-place along the last axis.  `b` is a view of `a`,\n",
    "    # so `a` is shuffled in place, too.\n",
    "    shp = b.shape[:-1]\n",
    "    for ndx in np.ndindex(shp):\n",
    "        np.random.shuffle(b[ndx])\n",
    "    return\n",
    "\n",
    "def augment(x,y,t=2):\n",
    "    xs,xn = [],[]\n",
    "    for i in range(t):\n",
    "        mask = y>0\n",
    "        x1 = x[mask].copy()\n",
    "        disarrange(x1,axis=0)\n",
    "        xs.append(x1)\n",
    "\n",
    "    for i in range(t//2):\n",
    "        mask = y==0\n",
    "        x1 = x[mask].copy()\n",
    "        disarrange(x1,axis=0)\n",
    "        xn.append(x1)\n",
    "\n",
    "    xs = np.vstack(xs)\n",
    "    xn = np.vstack(xn)\n",
    "    ys = np.ones(xs.shape[0])\n",
    "    yn = np.zeros(xn.shape[0])\n",
    "    x = np.vstack([x,xs,xn])\n",
    "    y = np.concatenate([y,ys,yn])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augment step\n",
    "x_train_a, y_train_a = augment(x_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#switch augmented data from array to dataframe\n",
    "#x_train_a_frame = pd.DataFrame(x_train_a)\n",
    "#y_train_a_frame = pd.DataFrame(y_train_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"the train_set_feature shape:\", x_train_a.shape)\n",
    "#print(\"the train_set_labels shape:\", y_train_a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NN **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the shape of the labels to 2.\n",
    "def to_one_hot(labels, dimension = 2):\n",
    "    results = np.zeros((len(labels),dimension))\n",
    "    for i, label in enumerate(labels):\n",
    "        results[i, label] = 1.\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_target shape: (200000, 2)\n"
     ]
    }
   ],
   "source": [
    "#one-hot labels\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "#y_train_a_vec = to_one_hot(y_train_a)\n",
    "print('train_target shape:', y_train_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random separate the train and vaild.\n",
    "#agumented data make the overfitting\n",
    "\n",
    "#rand_ind = np.random.permutation(420098)\n",
    "#train_ind = rand_ind[0:400000]\n",
    "#valid_ind = rand_ind[400000:420098]\n",
    "\n",
    "rand_ind = np.random.permutation(200000)\n",
    "train_ind = rand_ind[0:180000]\n",
    "valid_ind = rand_ind[180000:200000]\n",
    "\n",
    "x_valid_vec = x_train.iloc[valid_ind,:]\n",
    "y_valid_vec = y_train_vec[valid_ind,:]\n",
    "\n",
    "x_train_vec = x_train.iloc[train_ind,:]\n",
    "y_train_vec = y_train_vec[train_ind,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "#build NN model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(10, activation='relu', input_shape = (200,)))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(48, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 48)                1008      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               6272      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 59,560\n",
      "Trainable params: 59,560\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizers.RMSprop(lr=2E-4),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 180000 samples, validate on 20000 samples\n",
      "Epoch 1/50\n",
      "180000/180000 [==============================] - 25s 137us/step - loss: 0.3115 - acc: 0.8994 - val_loss: 0.2978 - val_acc: 0.8959\n",
      "Epoch 2/50\n",
      "180000/180000 [==============================] - 23s 127us/step - loss: 0.2821 - acc: 0.9019 - val_loss: 0.2881 - val_acc: 0.8992\n",
      "Epoch 3/50\n",
      "180000/180000 [==============================] - 23s 125us/step - loss: 0.2793 - acc: 0.9047 - val_loss: 0.2935 - val_acc: 0.9011\n",
      "Epoch 4/50\n",
      "180000/180000 [==============================] - 24s 132us/step - loss: 0.2854 - acc: 0.9060 - val_loss: 0.2689 - val_acc: 0.9030\n",
      "Epoch 5/50\n",
      "180000/180000 [==============================] - 23s 125us/step - loss: 0.2993 - acc: 0.9066 - val_loss: 0.2903 - val_acc: 0.9020\n",
      "Epoch 6/50\n",
      "180000/180000 [==============================] - 23s 125us/step - loss: 0.3479 - acc: 0.9065 - val_loss: 0.2982 - val_acc: 0.9038\n",
      "Epoch 7/50\n",
      "180000/180000 [==============================] - 23s 130us/step - loss: 0.3762 - acc: 0.9065 - val_loss: 0.3213 - val_acc: 0.9038\n",
      "Epoch 8/50\n",
      "180000/180000 [==============================] - 23s 127us/step - loss: 0.5587 - acc: 0.9024 - val_loss: 0.6931 - val_acc: 0.8959\n",
      "Epoch 9/50\n",
      "180000/180000 [==============================] - 22s 124us/step - loss: 0.6931 - acc: 0.8999 - val_loss: 0.6931 - val_acc: 0.8959\n",
      "Epoch 10/50\n",
      "180000/180000 [==============================] - 23s 128us/step - loss: 0.6931 - acc: 0.8999 - val_loss: 0.6931 - val_acc: 0.8959\n",
      "Epoch 11/50\n",
      "180000/180000 [==============================] - 24s 131us/step - loss: 0.6931 - acc: 0.8999 - val_loss: 0.6931 - val_acc: 0.8959\n",
      "Epoch 12/50\n",
      "180000/180000 [==============================] - 24s 133us/step - loss: 0.6931 - acc: 0.8999 - val_loss: 0.6931 - val_acc: 0.8959\n",
      "Epoch 13/50\n",
      "180000/180000 [==============================] - 22s 125us/step - loss: 0.6931 - acc: 0.8999 - val_loss: 0.6931 - val_acc: 0.8959\n",
      "Epoch 14/50\n",
      "148096/180000 [=======================>......] - ETA: 3s - loss: 0.6931 - acc: 0.8996"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_vec,y_train_vec,\n",
    "                  batch_size=32,epochs=50,\n",
    "                  validation_data=(x_valid_vec,y_valid_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame(model.predict(x_test))\n",
    "nn_result = np.array(prediction.columns[np.where(prediction!=0)[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **XBG**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits =4,random_state = 0,shuffle=False)\n",
    "for train_index, test_index in skf.split(x_train_a,y_train_a):\n",
    "    x_train_skf,x_val_skf = x_train_a[train_index],x_train_a[test_index]\n",
    "    y_train_skf,y_val_skf = y_train_a[train_index],y_train_a[test_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.611704\tvalidation_1-auc:0.611061\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 10 rounds.\n",
      "[1]\tvalidation_0-auc:0.684828\tvalidation_1-auc:0.681325\n",
      "[2]\tvalidation_0-auc:0.7181\tvalidation_1-auc:0.712595\n",
      "[3]\tvalidation_0-auc:0.742641\tvalidation_1-auc:0.732268\n",
      "[4]\tvalidation_0-auc:0.750097\tvalidation_1-auc:0.733779\n",
      "[5]\tvalidation_0-auc:0.765626\tvalidation_1-auc:0.743994\n",
      "[6]\tvalidation_0-auc:0.781835\tvalidation_1-auc:0.752629\n",
      "[7]\tvalidation_0-auc:0.799561\tvalidation_1-auc:0.760757\n",
      "[8]\tvalidation_0-auc:0.81259\tvalidation_1-auc:0.764111\n",
      "[9]\tvalidation_0-auc:0.835407\tvalidation_1-auc:0.774806\n",
      "[10]\tvalidation_0-auc:0.846516\tvalidation_1-auc:0.776946\n",
      "[11]\tvalidation_0-auc:0.857934\tvalidation_1-auc:0.784489\n",
      "[12]\tvalidation_0-auc:0.864364\tvalidation_1-auc:0.789417\n",
      "[13]\tvalidation_0-auc:0.869926\tvalidation_1-auc:0.793323\n",
      "[14]\tvalidation_0-auc:0.875611\tvalidation_1-auc:0.797371\n",
      "[15]\tvalidation_0-auc:0.881222\tvalidation_1-auc:0.801652\n",
      "[16]\tvalidation_0-auc:0.887998\tvalidation_1-auc:0.80788\n",
      "[17]\tvalidation_0-auc:0.894949\tvalidation_1-auc:0.815636\n",
      "[18]\tvalidation_0-auc:0.897196\tvalidation_1-auc:0.818388\n",
      "[19]\tvalidation_0-auc:0.90164\tvalidation_1-auc:0.822133\n",
      "[20]\tvalidation_0-auc:0.904271\tvalidation_1-auc:0.824505\n",
      "[21]\tvalidation_0-auc:0.908058\tvalidation_1-auc:0.827956\n",
      "[22]\tvalidation_0-auc:0.91167\tvalidation_1-auc:0.830231\n",
      "[23]\tvalidation_0-auc:0.915485\tvalidation_1-auc:0.834444\n",
      "[24]\tvalidation_0-auc:0.918321\tvalidation_1-auc:0.837049\n",
      "[25]\tvalidation_0-auc:0.921864\tvalidation_1-auc:0.839573\n",
      "[26]\tvalidation_0-auc:0.925087\tvalidation_1-auc:0.842211\n",
      "[27]\tvalidation_0-auc:0.92812\tvalidation_1-auc:0.845175\n",
      "[28]\tvalidation_0-auc:0.929641\tvalidation_1-auc:0.846838\n",
      "[29]\tvalidation_0-auc:0.932084\tvalidation_1-auc:0.849389\n",
      "[30]\tvalidation_0-auc:0.934049\tvalidation_1-auc:0.850963\n",
      "[31]\tvalidation_0-auc:0.936404\tvalidation_1-auc:0.852822\n",
      "[32]\tvalidation_0-auc:0.938519\tvalidation_1-auc:0.854611\n",
      "[33]\tvalidation_0-auc:0.940792\tvalidation_1-auc:0.856064\n",
      "[34]\tvalidation_0-auc:0.942428\tvalidation_1-auc:0.857051\n",
      "[35]\tvalidation_0-auc:0.944096\tvalidation_1-auc:0.858375\n",
      "[36]\tvalidation_0-auc:0.945794\tvalidation_1-auc:0.859865\n",
      "[37]\tvalidation_0-auc:0.947479\tvalidation_1-auc:0.860967\n",
      "[38]\tvalidation_0-auc:0.948762\tvalidation_1-auc:0.861669\n",
      "[39]\tvalidation_0-auc:0.950282\tvalidation_1-auc:0.862852\n",
      "[40]\tvalidation_0-auc:0.951516\tvalidation_1-auc:0.863494\n",
      "[41]\tvalidation_0-auc:0.952786\tvalidation_1-auc:0.864392\n",
      "[42]\tvalidation_0-auc:0.954015\tvalidation_1-auc:0.865221\n",
      "[43]\tvalidation_0-auc:0.955225\tvalidation_1-auc:0.866134\n",
      "[44]\tvalidation_0-auc:0.956472\tvalidation_1-auc:0.866916\n",
      "[45]\tvalidation_0-auc:0.957654\tvalidation_1-auc:0.867637\n",
      "[46]\tvalidation_0-auc:0.958878\tvalidation_1-auc:0.868285\n",
      "[47]\tvalidation_0-auc:0.959819\tvalidation_1-auc:0.868991\n",
      "[48]\tvalidation_0-auc:0.960826\tvalidation_1-auc:0.869442\n",
      "[49]\tvalidation_0-auc:0.961833\tvalidation_1-auc:0.870121\n",
      "[50]\tvalidation_0-auc:0.96278\tvalidation_1-auc:0.870517\n",
      "[51]\tvalidation_0-auc:0.963687\tvalidation_1-auc:0.871025\n",
      "[52]\tvalidation_0-auc:0.964541\tvalidation_1-auc:0.87157\n",
      "[53]\tvalidation_0-auc:0.96543\tvalidation_1-auc:0.872078\n",
      "[54]\tvalidation_0-auc:0.966272\tvalidation_1-auc:0.872561\n",
      "[55]\tvalidation_0-auc:0.967131\tvalidation_1-auc:0.873159\n",
      "[56]\tvalidation_0-auc:0.967813\tvalidation_1-auc:0.873453\n",
      "[57]\tvalidation_0-auc:0.968487\tvalidation_1-auc:0.873595\n",
      "[58]\tvalidation_0-auc:0.969223\tvalidation_1-auc:0.873978\n",
      "[59]\tvalidation_0-auc:0.969848\tvalidation_1-auc:0.874275\n",
      "[60]\tvalidation_0-auc:0.970559\tvalidation_1-auc:0.87459\n",
      "[61]\tvalidation_0-auc:0.971228\tvalidation_1-auc:0.87497\n",
      "[62]\tvalidation_0-auc:0.971829\tvalidation_1-auc:0.875265\n",
      "[63]\tvalidation_0-auc:0.972496\tvalidation_1-auc:0.875585\n",
      "[64]\tvalidation_0-auc:0.973006\tvalidation_1-auc:0.876035\n",
      "[65]\tvalidation_0-auc:0.973651\tvalidation_1-auc:0.876365\n",
      "[66]\tvalidation_0-auc:0.974288\tvalidation_1-auc:0.876667\n",
      "[67]\tvalidation_0-auc:0.974847\tvalidation_1-auc:0.876856\n",
      "[68]\tvalidation_0-auc:0.97537\tvalidation_1-auc:0.876994\n",
      "[69]\tvalidation_0-auc:0.975895\tvalidation_1-auc:0.877193\n",
      "[70]\tvalidation_0-auc:0.976391\tvalidation_1-auc:0.877328\n",
      "[71]\tvalidation_0-auc:0.976893\tvalidation_1-auc:0.877504\n",
      "[72]\tvalidation_0-auc:0.977401\tvalidation_1-auc:0.877603\n",
      "[73]\tvalidation_0-auc:0.97784\tvalidation_1-auc:0.877856\n",
      "[74]\tvalidation_0-auc:0.978251\tvalidation_1-auc:0.878062\n",
      "[75]\tvalidation_0-auc:0.97866\tvalidation_1-auc:0.878275\n",
      "[76]\tvalidation_0-auc:0.979093\tvalidation_1-auc:0.878468\n",
      "[77]\tvalidation_0-auc:0.979497\tvalidation_1-auc:0.878411\n",
      "[78]\tvalidation_0-auc:0.979955\tvalidation_1-auc:0.878611\n",
      "[79]\tvalidation_0-auc:0.980385\tvalidation_1-auc:0.87876\n",
      "[80]\tvalidation_0-auc:0.980802\tvalidation_1-auc:0.878949\n",
      "[81]\tvalidation_0-auc:0.981176\tvalidation_1-auc:0.879029\n",
      "[82]\tvalidation_0-auc:0.981526\tvalidation_1-auc:0.879184\n"
     ]
    }
   ],
   "source": [
    "clf = XGBClassifier(colsample_bylevel = 0.8015579071911014,\n",
    "        colsample_bytree = 0.44364889457651413,\n",
    "        gamma = 3.811128976537413e-05,\n",
    "        learning_rate = 0.2700390206185342,\n",
    "        max_delta_step = 18,\n",
    "        max_depth = 36,\n",
    "        min_child_weight = 2,\n",
    "        n_estimators = 83,\n",
    "        reg_alpha = 1.5057560255472018e-06,\n",
    "        reg_lambda = 0.08186810622382998,\n",
    "        scale_pos_weight = 0.02900459363415458,\n",
    "        subsample = 0.8835665823899177)\n",
    "clf.fit(x_train_skf,y_train_skf,eval_set = [(x_train_skf,y_train_skf),(x_val_skf,y_val_skf)],\n",
    "       eval_metric='auc',early_stopping_rounds=10)\n",
    "evals_results = clf.evals_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.0656,   7.7798,  12.9536, ...,  10.72  ,  15.4722,  -8.7197],\n",
       "       [  8.5304,   1.2543,  11.3047, ...,   9.8714,  19.1293, -20.976 ],\n",
       "       [  5.4827, -10.3581,  10.1407, ...,   7.0618,  19.8956, -23.1794],\n",
       "       ...,\n",
       "       [ 11.636 ,   2.2769,  11.2074, ...,   9.1933,  11.7905, -22.2762],\n",
       "       [ 13.5745,  -0.5134,  13.6584, ...,   8.1079,   8.7735,  -0.2122],\n",
       "       [ 10.4664,   1.807 ,  10.2277, ...,  10.3378,  14.334 ,  -7.7094]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_a = np.array(x_test)\n",
    "x_test_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_result = clf.predict(x_test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **LGB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "num_folds = 11\n",
    "features = [c for c in x_train.columns if c not in ['ID_code', 'target']]\n",
    "#target = x_train['target']\n",
    "\n",
    "folds = KFold(n_splits=num_folds, random_state=2319)\n",
    "#oof = np.zeros(len(x_train))\n",
    "#getVal = np.zeros(len(x_train))\n",
    "lgb_result = np.zeros(len(y_train))\n",
    "#feature_importance_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold idx:1\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.912229\tvalid_1's auc: 0.896459\n",
      "[10000]\ttraining's auc: 0.922006\tvalid_1's auc: 0.900289\n",
      "[15000]\ttraining's auc: 0.929514\tvalid_1's auc: 0.901064\n",
      "[20000]\ttraining's auc: 0.936353\tvalid_1's auc: 0.901116\n",
      "Early stopping, best iteration is:\n",
      "[17484]\ttraining's auc: 0.932962\tvalid_1's auc: 0.901285\n",
      "Fold idx:2\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.912059\tvalid_1's auc: 0.894891\n",
      "[10000]\ttraining's auc: 0.921827\tvalid_1's auc: 0.898231\n",
      "[15000]\ttraining's auc: 0.929416\tvalid_1's auc: 0.89854\n",
      "Early stopping, best iteration is:\n",
      "[13985]\ttraining's auc: 0.927946\tvalid_1's auc: 0.898677\n",
      "Fold idx:3\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.912995\tvalid_1's auc: 0.889396\n",
      "[10000]\ttraining's auc: 0.922797\tvalid_1's auc: 0.892885\n",
      "[15000]\ttraining's auc: 0.930287\tvalid_1's auc: 0.8932\n",
      "Early stopping, best iteration is:\n",
      "[13280]\ttraining's auc: 0.927795\tvalid_1's auc: 0.893258\n",
      "Fold idx:4\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.912486\tvalid_1's auc: 0.900409\n",
      "[10000]\ttraining's auc: 0.922392\tvalid_1's auc: 0.903228\n",
      "[15000]\ttraining's auc: 0.92987\tvalid_1's auc: 0.903501\n",
      "Early stopping, best iteration is:\n",
      "[13762]\ttraining's auc: 0.928094\tvalid_1's auc: 0.903567\n",
      "Fold idx:5\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.91279\tvalid_1's auc: 0.895819\n",
      "[10000]\ttraining's auc: 0.9226\tvalid_1's auc: 0.898758\n",
      "[15000]\ttraining's auc: 0.930114\tvalid_1's auc: 0.899127\n",
      "Early stopping, best iteration is:\n",
      "[14137]\ttraining's auc: 0.928887\tvalid_1's auc: 0.899267\n",
      "Fold idx:6\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.911921\tvalid_1's auc: 0.898799\n",
      "[10000]\ttraining's auc: 0.921962\tvalid_1's auc: 0.901887\n",
      "[15000]\ttraining's auc: 0.929545\tvalid_1's auc: 0.902026\n",
      "[20000]\ttraining's auc: 0.936386\tvalid_1's auc: 0.901798\n",
      "Early stopping, best iteration is:\n",
      "[17827]\ttraining's auc: 0.93348\tvalid_1's auc: 0.902199\n",
      "Fold idx:7\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.911551\tvalid_1's auc: 0.902333\n",
      "[10000]\ttraining's auc: 0.92147\tvalid_1's auc: 0.905086\n",
      "[15000]\ttraining's auc: 0.929003\tvalid_1's auc: 0.904985\n",
      "Early stopping, best iteration is:\n",
      "[11377]\ttraining's auc: 0.923642\tvalid_1's auc: 0.905313\n",
      "Fold idx:8\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.91236\tvalid_1's auc: 0.89692\n",
      "[10000]\ttraining's auc: 0.922179\tvalid_1's auc: 0.900013\n",
      "[15000]\ttraining's auc: 0.92965\tvalid_1's auc: 0.900374\n",
      "Early stopping, best iteration is:\n",
      "[13591]\ttraining's auc: 0.927604\tvalid_1's auc: 0.900441\n",
      "Fold idx:9\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.912169\tvalid_1's auc: 0.900352\n",
      "[10000]\ttraining's auc: 0.922066\tvalid_1's auc: 0.90407\n",
      "[15000]\ttraining's auc: 0.92958\tvalid_1's auc: 0.904342\n",
      "Early stopping, best iteration is:\n",
      "[13137]\ttraining's auc: 0.926894\tvalid_1's auc: 0.904416\n",
      "Fold idx:10\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.911488\tvalid_1's auc: 0.903481\n",
      "[10000]\ttraining's auc: 0.921416\tvalid_1's auc: 0.906449\n",
      "[15000]\ttraining's auc: 0.928973\tvalid_1's auc: 0.906657\n",
      "Early stopping, best iteration is:\n",
      "[13981]\ttraining's auc: 0.927498\tvalid_1's auc: 0.906758\n",
      "Fold idx:11\n",
      "Training until validation scores don't improve for 4000 rounds.\n",
      "[5000]\ttraining's auc: 0.911694\tvalid_1's auc: 0.896894\n",
      "[10000]\ttraining's auc: 0.921615\tvalid_1's auc: 0.899987\n",
      "[15000]\ttraining's auc: 0.929247\tvalid_1's auc: 0.900377\n",
      "Early stopping, best iteration is:\n",
      "[12922]\ttraining's auc: 0.926202\tvalid_1's auc: 0.90052\n"
     ]
    }
   ],
   "source": [
    "param = {\n",
    "    'bagging_freq': 5,\n",
    "    'bagging_fraction': 0.335,\n",
    "    'boost_from_average':'false',\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.041,\n",
    "    'learning_rate': 0.0083,\n",
    "    'max_depth': -1,\n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 80,\n",
    "    'min_sum_hessian_in_leaf': 10.0,\n",
    "    'num_leaves': 13,\n",
    "    'num_threads': 8,\n",
    "    'tree_learner': 'serial',\n",
    "    'objective': 'binary', \n",
    "    'verbosity': -1\n",
    "}\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train.values, y_train.values)):\n",
    "    \n",
    "    X_train_lgb, y_train_lgb = x_train.iloc[trn_idx], y_train.iloc[trn_idx]\n",
    "    X_valid_lgb, y_valid_lgb = x_train.iloc[val_idx], y_train.iloc[val_idx]\n",
    "    \n",
    "    X_tr, y_tr = augment(X_train_lgb.values, y_train_lgb.values)\n",
    "    X_tr = pd.DataFrame(X_tr)\n",
    "    \n",
    "    print(\"Fold idx:{}\".format(fold_ + 1))\n",
    "    trn_data = lgb.Dataset(X_tr, label=y_tr)\n",
    "    val_data = lgb.Dataset(X_valid_lgb, label=y_valid_lgb)\n",
    "    \n",
    "    clf = lgb.train(param, trn_data, 1000000, valid_sets = [trn_data, val_data], verbose_eval=5000, early_stopping_rounds = 4000)\n",
    "    #oof[val_idx] = clf.predict(x_train.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "    #getVal[val_idx]+= clf.predict(x_train.iloc[val_idx], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    #fold_importance_df = pd.DataFrame()\n",
    "    #fold_importance_df[\"feature\"] = features\n",
    "    #fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    #fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    #feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    lgb_result += clf.predict(x_test, num_iteration=clf.best_iteration) / folds.n_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (400000,) (200000,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-8ecb83eb1787>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnn_result\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxgb_result\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlgb_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (400000,) (200000,) "
     ]
    }
   ],
   "source": [
    "sample_submission['target'] = 0.3*nn_result + 0.4*xgb_result + 0.4*lgb_result\n",
    "sample_submission.to_csv('submission.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
